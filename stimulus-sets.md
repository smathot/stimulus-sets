<!-- This overview is available under a Creative Commons Attribution 3.0 Unported license -->

There are many sets of pictures and videos available that have been rated and standardized in various ways. These can be immensely useful as stimuli in psychological experiments.

The source of this overview can be found at <https://github.com/smathot/stimulus-sets/>. Feel free to submit additions, improvements, and corrections.

Overview
--------

Pictures:

- [Amsterdam library of object images (ALOI)](#aloi)
- [Bank of standardized stimuli (BOSS)](#boss)
- [Bonin et al.'s set of 299 pictures](#bonin)
- [CIPR still images](#cipr)
- [CNBC stimulus database](#cnbc)
- [Ecological alternative to Snodgrass & Vanderwart](#ecoalt)
- [Geneva affective picture database (GAPED)](#gaped)
- [HatField image test](#hatfield)
- [International affective pictures system (IAPS)](#iaps)
- [Natural scenes collection (nature/ campus scenes)](#natural_scenes_collection)
- [Nishimoto et al.'s set of 360 pictures](#nishimoto)
- [A pool of pairs of related objects (POPORO)](#poporo)
- [Psychological image collection at Stirling (PICS)](#pics)
- [evised Snodgrass and Vanderwart object pictorial set](#rsnod)
- [Snodgrass and Vanderwart object pictorial set](#snod)
- [UB KinFace Database](#kinface)
- [UPenn natural image database](#birthplace)

Videos:

- [Faces and motion Exeter databases (FAMED)](#famed)
- [Umla-Runge et al.'s action video clips](#umla-runge)

Amsterdam library of object images (ALOI) <a id='aloi'></a>
-----------------------------------------

**Description**: An extensive set of photos of small objects. The viewing angles and lighting conditions (illumination angle and color) have been systematically varied for each object. Stereo images ("3D") are also inluded.

**License**: ?

**Link**: <http://staff.science.uva.nl/~aloi/>

**Reference**: Geusebroek, J. M., Burghouts, G. J., & Smeulders, A. W. M. (2005). The Amsterdam library of object images. *International Journal of Computer Vision*, *61*(1), 103–112.

Bank of standardized stimuli (BOSS) <a id='boss'></a>
-----------------------------------

**Description**: A large set of full color photos of various objects. Highly recommended.

**License**: [Creative Commons Attribution-ShareAlike][cc-by-sa]

**Link**: <http://sites.google.com/site/mathieubrodeur/Home/boss>

**Reference 1**: Brodeur, M. B., Dionne-Dostie, E., Montreuil, T., & Lepage, M. (2010). The bank of standardized stimuli (BOSS), a new set of 480 normative photos of objects to be used as visual stimuli in cognitive research. *PloS ONE*, *5*(5), e10773

**Reference 2**: O'Sullivan, M., Lepage, M., Bouras, M., Montreuil, T., Brodeur, M. B. (2012). North-American norms for name disagreement: Pictorial stimuli naming discrepancies. *PLoS ONE*, *7*(10), e47802.

**Reference 3**: Brodeur, M. B., Kehayia, E., Dion-Lessard, G., Chauret, M., Montreuil, T., Dionne-Dostie, E., & Lepage, M. (2012). The bank of standardized stimuli (BOSS): comparison between French and English norms. *Behavior Research Methods*.

Bonin et al.'s set of 299 pictures <a id='bonin'></a>
----------------------------------

**Description**: A set of 299 black-and-white line drawings, with various normative ratings, such as name agreement (in French) and naming latency.

**License**: ?

**Link**: <http://leadserv.u-bourgogne.fr/bases/pictures/>

**Reference**: Bonin, P., Peereman, R., Malardier, N., Méot, A., & Chalard, M. (2003). A new set of 299 pictures for psycholinguistic studies: French norms for name agreement, image agreement, conceptual familiarity, visual complexity, image variability, age of acquisition, and naming latencies. *Behavior Research Methods, Instruments, & Computers*, *35*(1), 158-167.

CIPR still images <a id='cipr'></a>
-----------------

**Description**: A collection of images. Just images, no additional information is provided.

**License**: ?

**Link**: <http://www.cipr.rpi.edu/resource/stills/>

**References**: ?

Ecological alternative to Snodgrass and Vanderwart <a id='ecoalt'></a>
--------------------------------------------------

*A template based on this set is included with [OpenSesame][].*

**Description**: A set of 360 colour photographs of objects, animals, and scenes. Various normative ratings are available.

**License**: [Creative Commons Attribution][cc-by]

**Link**: <http://dx.plos.org/10.1371/journal.pone.0037527> (see Supporting information for download links)

**Reference**: Moreno-Martínez, F. J., & Montoro, P. R. (2012). An ecological alternative to Snodgrass & Vanderwart: 360 high quality colour images with norms for seven psycholinguistic variables. *PLoS One*, *7*(5), e37528

Faces and motion Exeter database (FAMED) <a id='famed'></a>
----------------------------------------

**Description**: A set of videos of 32 speaking male actors. Different viewpoints, headgear, and facial expressions are included.

**License**: Restrictive, but free for academic use.

**Link**: http://www.chrislongmore.co.uk/famed/index.html

**Reference**: ?

Geneva affective picture database (GAPED) <a id='gaped'></a>
-----------------------------------------

**Description**: Mostly scenes with a strong valence.

**License**: [Creative Commons Attribution-NonCommercial-ShareAlike][cc-by-nc]

**Link**: <http://www.affective-sciences.org/researchmaterial>

**Reference**: Dan-Glauser, E. S., & Scherer, K. R. (2011). The Geneva affective picture database (GAPED): a new 730-picture database focusing on valence and normative significance. *Behavior Research Methods*. doi:10.3758/s13428-011-0064-1

HatField image test <a id='hatfield'></a>
-------------------

**Description**: A set of high-quality colour photographs, chosen to span a wide range of categories and naming difficulties.

**License**: Described as 'free from copyright', but you do need to apply via an online form.

**Link**: <http://testbed.herts.ac.uk/HIT/hit_apply.asp>

**Reference**: Adlington, R. L., Laws, K. R., & Gale, T. M. (2009). The HatField image test: A new picture test and norms for experimental and clinical use. *Journal of Clinical and Experimental Neuropsychology*, *31*(6), 731-75.

International affective pictures system (IAPS) <a id='iaps'></a>
----------------------------------------------

**Description**: A collection of pictures that have been rated on valence, arousal and dominance. Unfortunately, you can't download these pictures directly, but you have to put in a request (see the link below). They are freely available for non-profit research, though.

**License**: ?

**Link**: <http://csea.phhp.ufl.edu/media.html>

**Reference**: Lang, P.J., Bradley, M.M., & Cuthbert, B.N. (2008). *International affective picture system (IAPS): Affective ratings of pictures and instruction manual. Technical Report A-8*. University of Florida, Gainseville, FL

Natural scenes collection (nature/ campus scenes) <a id='natural_scenes_collection'></a>
-------------------------------------------------

**Description**: Natural images of nature scenes containing no man-made objects or people (nature scene collection) and university campus scenes containing cars, building, and people (campus scene collection).

**License**: ?

**Link**: <http://www.cps.utexas.edu/natural_scenes/>

**Reference (for the campus scene collection)**: Burge, J., & Geisler, W. S. (2011). Optimal defocus estimation in individual natural images. *Proceedings of the National Academy of Sciences*, *108*(40), 16849–16854.

**Reference (for the natural scene collection)**: Geisler, W. S., & Perry, J. S. (2011). Statistics for optimal point prediction in natural images. Journal of Vision.

Nishimoto et al.'s set of 360 pictures <a id='nishimoto'></a>
--------------------------------------

**Description**: A collection of 360 black-and-white line drawings, with various norms for Japanese.

**License**: ?

**Link**: <http://www.springerlink.com/content/5v773074154063rt/13428_2011_Article_176_ESM.html>

**Reference**: Nishimoto, T., Ueda, T., Miyawaki, K., Une, Y., & Takahashi, M. (2012). The role of imagery-related properties in picture naming: A newly standardized set of 360 pictures for Japanese. *Behavior Research Methods*.

A pool of pairs of related objects (POPORO) <a id='poporo'></a>
-------------------------------------------

**Description**: A collection of pairs of objects with norms for semantic relatedness. Validated using both behavioural measures and EEG.

**License**: ?

**Link**: <http://www.oszillab.net/downloads.php>

**Reference**: Kovalenko, L.Y., Chaumon, M., & Busch, N.A. (2012). A pool of pairs of related objects (POPORO) for investigating visual semantic integration: Behavioral and electrophysiological validation. *Brain Topography*. doi:10.1007/s10548-011-0216-8

Psychological image collection at Stirling (PICS) <a id='pics'></a>
-------------------------------------------------

**Description**: A diverse collection of stimuli, including faces, objects and textures. Some ratings for the faces are also available.

**License**: ?

**Link**: <http://pics.psych.stir.ac.uk/>

**Reference**: The makers request that you simply cite the link above.

Revised Snodgrass and Vanderwart object pictorial set <a id='rsnod'></a>
-----------------------------------------------------

**Description**: Full color line drawings, derived from the original Snodgrass & Vanderwart set.

**License**: ?

**Link**: <http://www.nefy.ucl.ac.be/facecatlab/stimuli.htm>

**Reference**: Rossion, B., & Pourtois, G. (2004). Revisiting Snodgrass and Vanderwart’s object pictorial set: The role of surface detail in basic-level object recognition. *Perception*, *33*(2), 217-236.

Snodgrass and Vanderwart object pictorial set <a id='snod'></a>
---------------------------------------------

**Description**: A classic set of black and white line drawings. Apparently there are some licensing issues and, despite the fact that this is a widely known set of pictures, it seems hard to get a hold of them. I would recommend using the revised set by Rossion & Pourtois instead.

**Link**: ?

**License**: ?

**Reference**: Snodgrass, J. G., & Vanderwart, M. (1980). A standardized set of 260 pictures: Norms for name agreement, image agreement, familiarity, and visual complexity. *Journal of Experimental Psychology: Human Learning & Memory*, *6*(2), 174-215. doi:10.1037/0278-7393.6.2.174

UB KinFace Database <a id='kinface'></a>
-------------------

**Description**: A large set of photos of people with information about kinship (e.g., the person in photo X is the father of the person in photo Y).

**Link**: <http://www.cse.buffalo.edu/~yunfu/research/Kinface/Kinface.htm>

**License**: Free for academic use

**Reference**: Xia, S., Shao, M., & Fu, Y. (2011). Kinship verification through transfer learning. *International Joint Conferences on Artificial Intelligence*, 2539-2544.

Umla-Runge et al.'s action video clips <a id='umla-runge'></a>
-------------------------------------

**Description**: 784 videos of actions with familiarity ratings for Eastern and Western cultures.

**License**: ?

**Link**: <http://www.springerlink.com/content/b32254382l261350/13428_2012_Article_189_ESM.html>

**Reference**: Umla-Runge, K., Zimmer, H. D., Fu, X., & Wang, L. (2012). An action video clip database rated for familiarity in China and Germany. *Behavior Research Methods*.

UPenn natural image database <a id='birthplace'></a>
----------------------------

**Description**: A collection of photos of the Okavango Delta of Botswana, a savanna habitat where humans (and their eyes) presumably evolved. It's a bit quirky, perhaps, but I like the concept.

**License**: Creative Commons Attribution NonCommercial Unported 3.0 (CC by-NC)

**Link**: <http://tofu.psych.upenn.edu/~upennidb/>

**Reference**: Tkačik, G., Garrigan, P., Ratliff, C., Milčinski, G., Klein, J. M., Seyfarth, L. H., Sterling, P., et al. (2011). Natural images from the birthplace of the human eye. *PLoS ONE*, *6*(6), e20409. doi:10.1371/journal.pone.0020409

<!--
Template <a id=''></a>
--------

**Description**:

**License**:

**Link**:

**Reference**:
-->

[opensesame]: http://www.cogsci.nl/opensesame
[cc-by]: http://creativecommons.org/licenses/by/3.0
[cc-by-sa]: http://creativecommons.org/licenses/by-sa/3.0
[cc-by-nc]: http://creativecommons.org/licenses/by-nc/3.0